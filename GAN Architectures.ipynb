{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9bd546",
   "metadata": {},
   "source": [
    "# GAN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d5507",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df45d77a",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# python level imports\n",
    "import chess\n",
    "\n",
    "import chess.svg\n",
    "import cv2\n",
    "\n",
    "from IPython.display import display, SVG\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b917432f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:41:14.528222Z",
     "start_time": "2024-04-23T02:41:14.515271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Set default tensor type to CUDA tensors\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    " \n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "made_loader = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e440d30974945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:41:14.635390Z",
     "start_time": "2024-04-23T02:41:14.529220Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to empty cuda cache to avoid cuda memory issues\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4c10246dd3c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T01:48:39.383063Z",
     "start_time": "2024-04-23T01:48:37.701535Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to clear cuda from any point in code\n",
    "def clear_cuda():\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aced8f27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:41:14.667284Z",
     "start_time": "2024-04-23T02:41:14.653330Z"
    }
   },
   "outputs": [],
   "source": [
    "# import utils files\n",
    "from utils.Datasets import *\n",
    "\n",
    "import utils.Dataloading\n",
    "reload(utils.Dataloading)\n",
    "from utils.Dataloading import *\n",
    "from utils.Game_playing import *\n",
    "\n",
    "import utils.Playing_agents\n",
    "reload(utils.Playing_agents)\n",
    "from utils.Playing_agents import *\n",
    "\n",
    "from utils.CSV_data import *\n",
    "from utils.Puzzles import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e65cc4",
   "metadata": {},
   "source": [
    "## Behavioral Cloning Model and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e17ab646265886d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:41:14.682235Z",
     "start_time": "2024-04-23T02:41:14.668279Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model architecture taken from behavioral_cloning.ipynb\n",
    "class MLPv2_1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(14, 64, 3, 1, padding=1, padding_mode = 'zeros')\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.depth = 6\n",
    "\n",
    "        for _ in range(self.depth):\n",
    "            self.layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.layers.append(nn.BatchNorm2d(64))\n",
    "            self.layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.layers.append(nn.BatchNorm2d(64))\n",
    "\n",
    "        self.linear = nn.Linear(4096, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            j = i*4\n",
    "            ph = x.clone()\n",
    "            ph = self.layers[j](ph)\n",
    "            ph = self.layers[j+1](ph)\n",
    "            ph = F.relu(ph)\n",
    "            ph = self.layers[j+2](ph)\n",
    "            ph = self.layers[j+3](ph)\n",
    "\n",
    "            x = x + ph\n",
    "            x = F.relu(x)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        minn, ila = x[:,:64], x[:,64:]\n",
    "\n",
    "        return minn, ila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34154737e9a1cf50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:41:14.743553Z",
     "start_time": "2024-04-23T02:41:14.683239Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the behavioral cloning model from saved models\n",
    "RDv2 = torch.load(\"Models/RDv2.3 CB.pt\", map_location= device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02f81d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T20:32:25.603839Z",
     "start_time": "2024-04-12T20:21:12.149814Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_stockfish_data(N=2_000_000):\n",
    "\n",
    "    \"returns the boards, meta data, human moves and stockfish moves for N games\"\n",
    "    \n",
    "    file_path = \"Data/StockData.csv\"\n",
    "    new_data = True\n",
    "    epsilon = 1e-5\n",
    "    \n",
    "    df = pd.read_csv(file_path, nrows=N)\n",
    "    ind_map = index_map.cpu().numpy()\n",
    "    \n",
    "    \n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    \n",
    "    fens = np.array(df['FENs'])\n",
    "    moves = np.zeros((len(fens), 128))\n",
    "    h_moves = np.zeros((len(fens), 128))\n",
    "\n",
    "    bitboards, meta = zip(*[fen_to_board(x) for x in tqdm(fens, total=len(fens))])\n",
    "    \n",
    "    bitboards = np.asarray(bitboards)\n",
    "\n",
    "    meta = np.asarray(meta)\n",
    "    \n",
    "    if new_data:\n",
    "\n",
    "        moves[df.index,df['stock_moves'].apply(lambda x: chess.Move.from_uci(x).from_square)] = 1\n",
    "        moves[df.index, 64 + df['stock_moves'].apply(lambda x: chess.Move.from_uci(x).to_square)] = 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for i in tqdm(range(4)):\n",
    "            \n",
    "            moves[df.index,df[f'move{i}'].apply(lambda x: chess.Move.from_uci(x).from_square)] += df[f'eval{i}'] + epsilon\n",
    "            moves[df.index, 64 + df[f'move{i}'].apply(lambda x: chess.Move.from_uci(x).to_square)] += df[f'eval{i}'] + epsilon\n",
    "        \n",
    "    \n",
    "    h_moves[df.index, df[\"hmoves\"].apply(lambda x: chess.Move.from_uci(x).from_square)] = 1\n",
    "    h_moves[df.index, 64 + df[\"hmoves\"].apply(lambda x: chess.Move.from_uci(x).to_square)] = 1\n",
    "    \n",
    "    flipped_moves = np.zeros_like(moves)    \n",
    "    flipped_moves[:,:64] = moves[:,ind_map]\n",
    "    flipped_moves[:,64:] = moves[:,64+ind_map]\n",
    "    #v_fens = np.vectorize(fen_to_board)\n",
    "    moves = np.where(np.expand_dims(meta, 1), moves, flipped_moves)\n",
    "\n",
    "    flipped_moves = np.zeros_like(h_moves)\n",
    "    flipped_moves[:,:64] = h_moves[:,ind_map]\n",
    "    flipped_moves[:,64:] = h_moves[:,64+ind_map]\n",
    "    #v_fens = np.vectorize(fen_to_board)\n",
    "    h_moves = np.where(np.expand_dims(meta, 1), h_moves, flipped_moves)\n",
    "    \n",
    "    #bitboards = np.array(list(map(fen_to_board, fens)))\n",
    "    \n",
    "    del df\n",
    "    \n",
    "    \n",
    "    return bitboards, meta, h_moves, moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download N boards of data\n",
    "boards, meta, human_moves, stock_moves = load_stockfish_data(N = 500_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b97cf",
   "metadata": {},
   "source": [
    "## BasicGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab89efa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:41:14.758506Z",
     "start_time": "2024-04-23T02:41:14.745547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here, we define the generator architecture for the GAN\n",
    "# Uncomment commented lines to run with BatchNorm\n",
    "class generator_1(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_depth):\n",
    "\n",
    "        \"\"\"\n",
    "        Defines the generator architecture\n",
    "\n",
    "        :param conv_depth: int\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(14, 64, 3, 1, padding=1, padding_mode = 'zeros')\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_depth = conv_depth\n",
    "        \n",
    "        for i in range(self.conv_depth):\n",
    "            self.conv_layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            #self.conv_layers.append(nn.BatchNorm2d(64))\n",
    "            self.conv_layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            #if i < self.conv_depth - 1:\n",
    "                #self.conv_layers.append(nn.BatchNorm2d(64))\n",
    "\n",
    "        self.linear = nn.Linear(4096, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Takes in a board and outputs the move probabilities\n",
    "\n",
    "        :param x: 14x8x8 chess bitboard\n",
    "        :return: 128x1 move vector\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        for i in range(self.conv_depth):\n",
    "            j = i*2\n",
    "            ph = x.clone()\n",
    "            ph = self.conv_layers[j](ph)\n",
    "            #ph = self.conv_layers[j+1](ph)\n",
    "            ph = F.relu(ph)\n",
    "            ph = self.conv_layers[j+1](ph)\n",
    "            #if i < self.conv_depth - 1:\n",
    "                #ph = self.conv_layers[j+3](ph)\n",
    "            \n",
    "            x = x + ph\n",
    "            x = F.relu(x)   \n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        minn, ila = x[:,:64], x[:,64:]\n",
    "\n",
    "        minn = F.softmax(minn, dim=1)\n",
    "        ila = F.softmax(ila, dim=1)\n",
    "\n",
    "        return torch.cat([minn, ila], dim=1).view(-1, 2, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da16f337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:41:14.773452Z",
     "start_time": "2024-04-23T02:41:14.759500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we define the architecture of the discriminator in the GAN architecture\n",
    "class discriminator_1(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_depth):\n",
    "\n",
    "        \"\"\"\n",
    "        Defines the discriminator architecture\n",
    "\n",
    "        :param conv_depth: int\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(16, 64, 3, 1, padding=1, padding_mode = 'zeros')\n",
    "\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_depth = conv_depth\n",
    "\n",
    "        for _ in range(self.conv_depth):\n",
    "            self.conv_layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.conv_layers.append(nn.LayerNorm([64,8,8]))\n",
    "            self.conv_layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.conv_layers.append(nn.LayerNorm([64,8,8]))\n",
    "            \n",
    "        self.linear = nn.Linear(4096, 1)\n",
    "    \n",
    "\n",
    "    def forward(self, board, move):\n",
    "        \"\"\"\n",
    "        Takes in a board and outputs the move probabilities\n",
    "\n",
    "        :param board: 14x8x8 chess bitboard\n",
    "        :param move: 128x1 move vector\n",
    "        :return: probability of move being played by human\n",
    "        \"\"\"\n",
    "        \n",
    "        x = torch.cat((board, move), dim = 1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        for i in range(self.conv_depth):\n",
    "            j = i*2\n",
    "            ph = x.clone()\n",
    "            ph = self.conv_layers[j](ph)\n",
    "            ph = self.conv_layers[j+1](ph)\n",
    "            ph = F.leaky_relu(ph)\n",
    "            ph = self.conv_layers[j+2](ph)\n",
    "            ph = self.conv_layers[j+3](ph)\n",
    "            \n",
    "            x = x + ph\n",
    "            x = F.leaky_relu(x)\n",
    "                  \n",
    "                  \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf3c6fec864d134d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T13:49:05.016900Z",
     "start_time": "2024-04-23T13:49:04.946719Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We defind the final BasicGAN architecture\n",
    "class GAN_1(nn.Module):\n",
    "    #AI: 0, Human: 1\n",
    "    def __init__(self, g_conv_depth, d_conv_depth, lr, pre_trained_g = None):\n",
    "\n",
    "        \"\"\"\n",
    "        Defines the BasicGAN architecture\n",
    "\n",
    "        :param g_conv_depth: int \n",
    "        :param d_conv_depth: int\n",
    "        :param lr: float\n",
    "        :param pre_trained_g: a previous network on which to train \n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.save_every = 2 # defines how often to save the GAN models\n",
    "\n",
    "        self.alpha = 0.2\n",
    "        \n",
    "        # if we have a pre-trained model then make it the generator\n",
    "        if pre_trained_g is not None:\n",
    "            \n",
    "            self.generator = pre_trained_g\n",
    "            self.pre_trained = True\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.generator = generator_1(g_conv_depth)\n",
    "            self.pre_trained = False\n",
    "\n",
    "\n",
    "        # define the current discriminator as specified above\n",
    "        self.discriminator = discriminator_1(d_conv_depth)\n",
    "        \n",
    "        # dict to store important model statistics such as validation accuracy and loss\n",
    "        self.logs = {\"g_acc\": [0], \"d_acc_r\": [0], \"d_acc_f\": [0], \n",
    "                     \"g_loss\": [0], \"d_loss\": [0],\"d_dist_f\": [0], \"d_dist_r\": [0], \n",
    "                     \"cur_g_loss\": 0, \"cur_d_loss\": 0}\n",
    "        \n",
    "        # this is to ensure a dataloader is in place\n",
    "        self.made_loader = False\n",
    "        \n",
    "        # set up the optimizers and appropriate loss functions\n",
    "        self.configure_optimizers(lr)\n",
    "        self.categorical_loss_1 = torch.nn.CrossEntropyLoss()\n",
    "        self.categorical_loss_2 = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "    # running the GAN is the same as running the generator\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "    \n",
    "    # function that defines chosen loss function for the discriminator\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "    \n",
    "    \n",
    "    # this function is not used in BasicGAN. Only in StockGAN\n",
    "    # this function trains the generator on the optimal stockfish moves\n",
    "    def stockfish_train(self, train_boards, moves):\n",
    "\n",
    "        \n",
    "        self.generator.train()\n",
    "        \n",
    "        self.discriminator.eval()\n",
    "        \n",
    "        self.opt_g.zero_grad()\n",
    "\n",
    "        fake_moves = self(train_boards)\n",
    "\n",
    "        moves = moves.view(-1, 128)\n",
    "\n",
    "        if self.pre_trained:\n",
    "\n",
    "            fake_moves = F.softmax(fake_moves[0], dim=1), F.softmax(fake_moves[1], dim=1)\n",
    "            g_loss = self.categorical_loss_1(fake_moves[0], moves[:,:64]) + self.categorical_loss_2(fake_moves[1], moves[:,64:])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            fake_moves = fake_moves.view(-1, 128)\n",
    "\n",
    "            g_loss = self.categorical_loss_1(fake_moves[:,:64], moves[:,:64]) + self.categorical_loss_2(fake_moves[:,64:], moves[:,64:])\n",
    "            \n",
    "        #g_loss = torch.sum(torch.log((y - y_hat) + epsilon), dim=0)\n",
    "        \n",
    "        g_loss *= self.alpha\n",
    "\n",
    "        self.logs[\"cur_g_loss\"] += g_loss.item()\n",
    "\n",
    "        g_loss.backward()\n",
    "\n",
    "        self.opt_g.step()\n",
    "    \n",
    "    # this function trains the generator based on discriminator if train_generator is True\n",
    "    # If train_generator is False, then the discriminaotr is trained\n",
    "    def train_step(self, train_boards, real_moves, train_generator, prev_generator=None):\n",
    "\n",
    "        self.discriminator.train()\n",
    "\n",
    "        self.generator.train()\n",
    "\n",
    "        epsilon = 1e-8\n",
    "        \n",
    "        #train generator\n",
    "        if train_generator:\n",
    "            \n",
    "            self.discriminator.eval()\n",
    "\n",
    "            self.opt_g.zero_grad()\n",
    "            \n",
    "            fake_moves = self(train_boards)\n",
    "            \n",
    "            if self.pre_trained:\n",
    "                \n",
    "                fake_moves = F.softmax(fake_moves[0], dim=1), F.softmax(fake_moves[1], dim=1)\n",
    "                fake_moves = self.diffable_argmax_moves(torch.cat(fake_moves,dim=1)).view(-1,2,8,8)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                fake_moves = self.diffable_argmax_moves(fake_moves).view(-1,2,8,8)\n",
    "            \n",
    "            y_hat = self.discriminator(train_boards, fake_moves)\n",
    "            \n",
    "            y = torch.zeros(real_moves.size(0), 1).to(device)\n",
    "            \n",
    "            g_loss = -1 * self.adversarial_loss(y_hat, y)\n",
    "                        \n",
    "            self.logs[\"cur_g_loss\"] += g_loss.item()\n",
    "            \n",
    "            g_loss.backward()\n",
    "\n",
    "            self.opt_g.step()\n",
    "              \n",
    "        #discriminator training \n",
    "        else:\n",
    "\n",
    "            self.generator.eval()\n",
    "\n",
    "            self.opt_d.zero_grad()\n",
    "            \n",
    "            y_hat_real = self.discriminator(train_boards, real_moves)\n",
    "            y_real = torch.ones(real_moves.size(0), 1).to(device)\n",
    "            \n",
    "            d_real_loss = self.adversarial_loss(y_hat_real, y_real)\n",
    "            \n",
    "            if prev_generator is not None:\n",
    "                \n",
    "                prev_fake_moves = prev_generator(train_boards[:len(train_boards)//8])\n",
    "                fake_moves = self(train_boards[len(train_boards)//8:])\n",
    "\n",
    "                if self.pre_trained:\n",
    "\n",
    "                    fake_moves = F.softmax(fake_moves[0], dim=1), F.softmax(fake_moves[1], dim=1)\n",
    "                    fake_moves = self.diffable_argmax_moves(torch.cat(fake_moves,dim=1)).view(-1,2,8,8).detach()\n",
    "                    prev_fake_moves = F.softmax(prev_fake_moves[0], dim=1), F.softmax(prev_fake_moves[1], dim=1)\n",
    "                    prev_fake_moves = self.diffable_argmax_moves((torch.cat(prev_fake_moves,dim=1))).view(-1,2,8,8).detach()\n",
    "\n",
    "                else:\n",
    "\n",
    "                    fake_moves = self.diffable_argmax_moves(fake_moves).view(-1,2,8,8).detach()\n",
    "                    prev_fake_moves = self.diffable_argmax_moves(prev_fake_moves).view(-1,2,8,8).detach()\n",
    "                \n",
    "                fake_moves = torch.cat([prev_fake_moves, fake_moves], dim=0)\n",
    "\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                fake_moves = self(train_boards)\n",
    "\n",
    "                if self.pre_trained:\n",
    "                    fake_moves = F.softmax(fake_moves[0], dim=1), F.softmax(fake_moves[1], dim=1)\n",
    "                    fake_moves = self.diffable_argmax_moves(torch.cat(fake_moves,dim=1)).view(-1,2,8,8).detach()\n",
    "\n",
    "                else:\n",
    "\n",
    "                    fake_moves = self.diffable_argmax_moves(fake_moves).view(-1,2,8,8).detach()\n",
    "\n",
    "            \n",
    "            y_hat_fake = self.discriminator(train_boards, fake_moves)\n",
    "            y_fake = torch.zeros(real_moves.size(0), 1).to(device)\n",
    "\n",
    "            d_fake_loss = self.adversarial_loss(y_hat_fake, y_fake)\n",
    "            \n",
    "            \n",
    "            d_loss = d_fake_loss + d_real_loss\n",
    "            self.logs[\"cur_d_loss\"] += d_loss.item()\n",
    "            \n",
    "            d_loss.backward()\n",
    "\n",
    "            self.opt_d.step()\n",
    "\n",
    "    \n",
    "    def diffable_argmax_moves(self, moves):\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        Our approximation of the Gumble-Softmax\n",
    "\n",
    "        :param moves: 128x1 vector of moves\n",
    "\n",
    "        :return: a 1 in the most likely in index of from_square and to_square and 0s elsewhere\n",
    "        \"\"\"\n",
    "        \n",
    "        moves = moves.view(-1,2,64)\n",
    "        # Create a tensor to hold the transformed results\n",
    "        transformed_tensor = torch.zeros_like(moves).to(device)\n",
    "    \n",
    "        # Find the indices of the maximum values along the last two dimensions\n",
    "        max_indices = torch.argmax(moves, dim=2, keepdim=True).to(device) # 5000, 2\n",
    "    \n",
    "        # Create a mask where the maximum indices are set to 1\n",
    "        idx0 = torch.arange(transformed_tensor.size(0)).unsqueeze(1).unsqueeze(2).to(device)\n",
    "        idx1 = torch.arange(transformed_tensor.size(1)).unsqueeze(0).unsqueeze(2).to(device)\n",
    "    \n",
    "        transformed_tensor[idx0, idx1, max_indices] = 1\n",
    "        \n",
    "        moves = moves * transformed_tensor\n",
    "\n",
    "        moves /= moves[idx0, idx1, max_indices]\n",
    "    \n",
    "        return moves\n",
    "            \n",
    "    # sets up the optimizers given the learning rate\n",
    "    def configure_optimizers(self, lr):\n",
    "        self.lr = lr\n",
    "        self.opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas = (0.5, 0.999),  weight_decay=0.0)\n",
    "        self.opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr,  betas = (0.5, 0.999), weight_decay=0.0)\n",
    "    \n",
    "    # on epoch end, compute the necessary statistics for self.logs such as val accuracy\n",
    "    def on_epoch_end(self, epoch, G, prefix, val_data=None):\n",
    "        \n",
    "        self.logs[\"g_loss\"].append(self.logs[\"cur_g_loss\"] / G)\n",
    "        self.logs[\"d_loss\"].append(self.logs[\"cur_d_loss\"] / G)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} with g_loss: {self.logs[\"cur_g_loss\"] / G} and d_loss: {self.logs[\"cur_d_loss\"] / G}')\n",
    "        \n",
    "        self.logs[\"cur_g_loss\"] = 0\n",
    "        self.logs[\"cur_d_loss\"] = 0\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            \n",
    "            if val_data is not None:\n",
    "                \n",
    "                self.discriminator.eval()\n",
    "                \n",
    "                self.generator.eval()\n",
    "                \n",
    "                val_boards = val_data.bitboards\n",
    "                real_moves = val_data.moves\n",
    "                \n",
    "                #fake_moves_ind = torch.argmax(fake_moves, dim=1)\n",
    "                values = np.zeros(5)\n",
    "                \n",
    "                for i in range(0,len(val_boards), 100):\n",
    "                \n",
    "                    with torch.no_grad():\n",
    "                        \n",
    "                        curr_boards, curr_moves = val_boards[i:i+100], real_moves[i:i+100]\n",
    "    \n",
    "                        fake_moves = self(curr_boards)\n",
    "                                                \n",
    "                        if self.pre_trained:\n",
    "                            \n",
    "                            fake_from_moves = torch.argmax(fake_moves[0], dim=1)\n",
    "                            fake_to_moves = torch.argmax(fake_moves[1], dim=1)\n",
    "                            real_from_moves = torch.argmax(curr_moves[:,0].view(-1,64), dim=1)\n",
    "                            real_to_moves = torch.argmax(curr_moves[:,1].view(-1,64), dim=1)\n",
    "                            values[4] += torch.sum((fake_from_moves == real_from_moves) & (fake_to_moves == real_to_moves)).item()/fake_from_moves.size(0)\n",
    "                        \n",
    "                            fake_moves = self.diffable_argmax_moves(torch.cat([F.softmax(fake_moves[0], dim=1), F.softmax(fake_moves[1], dim=1)], dim=1)).view(-1,2,8,8)\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            fake_moves = self.diffable_argmax_moves(fake_moves).view(-1,2,8,8)\n",
    "\n",
    "\n",
    "                        f_pred = self.discriminator(curr_boards, fake_moves)\n",
    "                        r_pred = self.discriminator(curr_boards, curr_moves)\n",
    "    \n",
    "                        values[0] += torch.mean(torch.round(f_pred) == 0, dtype=torch.float).item() #d_acc_f\n",
    "                        values[1] += torch.mean(torch.round(r_pred) == 1, dtype=torch.float).item() #d_acc_r\n",
    "    \n",
    "                        values[2] += torch.mean(torch.abs(f_pred)) #d_dist_f\n",
    "                        values[3] += torch.mean(torch.abs(1 - r_pred)) #d_dist_r\n",
    "\n",
    "                        if not self.pre_trained:\n",
    "    \n",
    "                            values[4] += torch.mean((curr_moves.view(-1,128) == torch.round(fake_moves).view(-1,128)).all(dim=1), dtype=torch.float).item() # g_acc\n",
    "                                                    \n",
    "                n = int(len(val_boards) // 100)\n",
    "                d_acc_f, d_acc_r = values[0] / n, values[1] / n\n",
    "                d_dist_f, d_dist_r = values[2] / n, values[3] / n\n",
    "                g_acc = values[4] / n\n",
    "                \n",
    "                print(f'Epoch: {epoch+1}, {g_acc=}, {d_acc_f=}, {d_acc_r=}')\n",
    "                print(f\"{d_dist_f=}, {d_dist_r=}\")\n",
    "                \n",
    "                self.logs[\"d_acc_f\"].append(d_acc_f)\n",
    "                self.logs[\"d_acc_r\"].append(d_acc_r)\n",
    "                self.logs[\"d_dist_f\"].append(d_dist_f)\n",
    "                self.logs[\"d_dist_r\"].append(d_dist_r)\n",
    "                self.logs[\"g_acc\"].append(g_acc)\n",
    "                \n",
    "                \n",
    "            if epoch % self.save_every == 0:\n",
    "            \n",
    "                torch.save(self.generator, f\"{prefix}-generator {epoch}.pt\")\n",
    "                torch.save(self.discriminator, f\"{prefix}-discriminator {epoch}.pt\")\n",
    "            \n",
    "    # create the dataloader given the boards, meta, moves array as well as batch size, number of training and validation points\n",
    "    def create_dataloader(self, boards, meta, moves, B, N, N_val):\n",
    "\n",
    "        if self.made_loader:\n",
    "\n",
    "            clear_cuda()\n",
    "            \n",
    "        loader = DataLoader(GANData(boards[:N], meta[:N], moves[:N]), batch_size = B, shuffle = True, generator=torch.Generator(device=device))\n",
    "        val_loader = GANData(boards[N:N+N_val], meta[N:N+N_val], moves[N:N+N_val])\n",
    "        \n",
    "        self.made_loader = True\n",
    "        \n",
    "        return loader, val_loader\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4677947170615bf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:41:14.852910Z",
     "start_time": "2024-04-23T02:41:14.838756Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This sets up the Dataset for batch retrievals in training\n",
    "class GANData(Dataset):\n",
    "\n",
    "    # converts moves and boards to tensors\n",
    "    def __init__(self, bitboards, meta, moves):\n",
    "\n",
    "        self.bitboards = torch.tensor(bitboards, dtype = torch.float).to(device)\n",
    "\n",
    "        self.moves = torch.tensor(moves.reshape(-1,2,8,8), dtype = torch.float).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.moves.size(dim=0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.bitboards[idx], self.moves[idx]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0cc09a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T18:57:58.151770Z",
     "start_time": "2024-04-21T18:57:58.129839Z"
    }
   },
   "outputs": [],
   "source": [
    "# make instance of model and dataloader\n",
    "RSv1 = GAN_1(g_conv_depth=6, d_conv_depth=6, lr=0.0002, pre_trained_g=None).to(device)\n",
    "loader, val_data = RSv1.create_dataloader(boards, meta, human_moves, B = 128, N=len(boards)-4_001, N_val=4_000) # try B = 128\n",
    "G = len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c01df55c0590460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T00:02:09.806354Z",
     "start_time": "2024-04-18T00:02:09.793344Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#modify the generator with best empirically found learning rate\n",
    "RSv1.opt_g = torch.optim.Adam(RSv1.generator.parameters(), lr=0.00075, betas = (0.5, 0.999),  weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2eb6651643a9eb0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T18:22:39.848411Z",
     "start_time": "2024-04-21T18:22:39.833457Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these control the number of iterations that the discriminator and generator train on to mitigate model collapse\n",
    "train_discriminator = False\n",
    "train_all = True\n",
    "train_generator = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8d8dc6ba5615510",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T18:22:39.880258Z",
     "start_time": "2024-04-21T18:22:39.865352Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# these are constants that help control how many times each model trains before moving to the next\n",
    "save_thresh = 0\n",
    "r_bound, f_bound = 0.75,0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecb55a7a2f10f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T19:05:54.666263Z",
     "start_time": "2024-04-21T18:58:00.623354Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "prefix = \"BasicGAN\"\n",
    "for epoch in range(0,50):\n",
    "\n",
    "    reps = 0\n",
    "\n",
    "    if train_all or train_discriminator:\n",
    "        prev_generator = None\n",
    "\n",
    "        if epoch > RSv1.save_every + 1 and not (RSv1.logs['d_acc_f'][-1] > f_bound and RSv1.logs['d_acc_r'][-1] > r_bound):\n",
    "            choice = np.random.choice(np.arange(start=RSv1.save_every, stop= (epoch//(RSv1.save_every+1) * RSv1.save_every)+1, step = RSv1.save_every))\n",
    "\n",
    "            prev_generator = torch.load(f'{prefix}-generator {choice}.pt', map_location= device)\n",
    "    \n",
    "        while not (RSv1.logs['d_acc_f'][-1] > f_bound and RSv1.logs['d_acc_r'][-1] > r_bound):\n",
    "            \n",
    "            reps += 1\n",
    "            if reps > 20:\n",
    "                train_all = False\n",
    "                train_discriminator = False\n",
    "                train_generator = False\n",
    "                break\n",
    "\n",
    "            i=0\n",
    "            \n",
    "            for bitboards, mvs in tqdm(loader):\n",
    "                if i > G // 2:\n",
    "                    break\n",
    "                RSv1.train_step(bitboards, mvs, train_generator=False, prev_generator=prev_generator)\n",
    "                i += 1\n",
    "\n",
    "            print('Discriminator Training')\n",
    "            RSv1.on_epoch_end(epoch, G,  prefix, val_data)\n",
    "\n",
    "\n",
    "    reps = 0\n",
    "    if train_all or train_generator:\n",
    "        while (RSv1.logs['d_acc_f'][-1] > f_bound and RSv1.logs['d_acc_r'][-1] > r_bound):\n",
    "            reps += 1\n",
    "            if reps > 20:\n",
    "                train_all = False\n",
    "                train_generator = False\n",
    "                train_discriminator = False\n",
    "                break\n",
    "\n",
    "            i=0\n",
    "            for bitboards, mvs in tqdm(loader):\n",
    "\n",
    "                if i > G // 1:\n",
    "                   break\n",
    "\n",
    "                RSv1.train_step(bitboards, mvs, train_generator=True)\n",
    "                i += 1\n",
    "            \n",
    "            print('Generator Training')\n",
    "            RSv1.on_epoch_end(epoch, G,  prefix,  val_data)\n",
    "            \n",
    "            if RSv1.logs[\"g_acc\"][-1] > save_thresh:\n",
    "                save_thresh = RSv1.logs[\"g_acc\"][-1]\n",
    "                torch.save(RSv1.generator, f\"StockGAN_RDv2_acc{save_thresh}.pt\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc343b0b178b4c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stockfish GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db829524ce5a783b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:50:10.384228Z",
     "start_time": "2024-04-23T02:50:10.339377Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we modify our previoud GANData to also include stockfish moves when training StockGAN\n",
    "class StockData(Dataset):\n",
    "\n",
    "    def __init__(self, bitboards, moves, stock_moves):\n",
    "\n",
    "        self.bitboards = torch.tensor(bitboards, dtype = torch.float).to(device)\n",
    "\n",
    "        self.moves = torch.tensor(moves, dtype = torch.float).view(-1,2,8,8).to(device)\n",
    "        self.stock_moves = torch.tensor(stock_moves, dtype=torch.float).view(-1,2,8,8).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.moves.size(dim=0)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.bitboards[idx], self.moves[idx], self.stock_moves[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2645f10c27291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:05:47.218162Z",
     "start_time": "2024-04-23T14:05:47.190260Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Like BasicGAN, make an instance of the model and set up datasets\n",
    "RSv1 = GAN_1(g_conv_depth=6, d_conv_depth=6, lr=0.0002, pre_trained_g=RDv2).to(device)\n",
    "val_size = 2_000\n",
    "B = 128\n",
    "loader = DataLoader(StockData(boards[:-val_size], human_moves[:-val_size], stock_moves[:-val_size]), batch_size = B, shuffle = True, generator=torch.Generator(device=device))\n",
    "val_data = StockData(boards[-val_size:], human_moves[-val_size:], stock_moves[-val_size:])\n",
    "G = len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "954f59800fd8ceec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T15:09:26.195134Z",
     "start_time": "2024-04-23T15:09:26.188158Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same use as BasicGAN\n",
    "\n",
    "train_discriminator = False\n",
    "train_all = True\n",
    "train_generator = False\n",
    "\n",
    "r_bound, f_bound = 0.6, 0.6\n",
    "save_thresh = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bdcbed9d95856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T15:52:53.822192Z",
     "start_time": "2024-04-23T15:41:43.582242Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "prefix = \"StockGAN-RDv2\"\n",
    "for epoch in range(50):\n",
    "\n",
    "    reps = 0\n",
    "\n",
    "    if train_all or train_discriminator:\n",
    "        prev_generator = None\n",
    "\n",
    "        if epoch > RSv1.save_every + 1 and not (RSv1.logs['d_acc_f'][-1] > f_bound and RSv1.logs['d_acc_r'][-1] > r_bound):\n",
    "            choice = np.random.choice(np.arange(start=RSv1.save_every, stop= (epoch//(RSv1.save_every+1) * RSv1.save_every)+1, step = RSv1.save_every))\n",
    "\n",
    "            prev_generator = torch.load(f'{prefix}-generator {choice}.pt', map_location= device)\n",
    "\n",
    "        while not (RSv1.logs['d_acc_f'][-1] > f_bound and RSv1.logs['d_acc_r'][-1] > r_bound):\n",
    "\n",
    "            reps += 1\n",
    "            if reps > 20:\n",
    "                train_all = False\n",
    "                train_discriminator = False\n",
    "                train_generator = False\n",
    "                break\n",
    "\n",
    "            i=0\n",
    "\n",
    "            for bitboards, mvs, _ in tqdm(loader):\n",
    "                if i > G // 1:\n",
    "                    break\n",
    "                RSv1.train_step(bitboards, mvs, train_generator=False, prev_generator=prev_generator)\n",
    "                i += 1\n",
    "\n",
    "            print('Discriminator Training')\n",
    "            RSv1.on_epoch_end(epoch, G, prefix, val_data)\n",
    "\n",
    "\n",
    "    reps = 0\n",
    "    if train_all or train_generator:\n",
    "\n",
    "        while (RSv1.logs['d_acc_f'][-1] > f_bound and RSv1.logs['d_acc_r'][-1] > r_bound):\n",
    "            reps += 1\n",
    "            if reps > 20:\n",
    "                train_all = False\n",
    "                train_generator = False\n",
    "                train_discriminator = False\n",
    "                break\n",
    "\n",
    "            i=0\n",
    "            for bitboards, mvs, stk_mvs in tqdm(loader):\n",
    "                if i > G // 1:\n",
    "                    break\n",
    "\n",
    "                RSv1.train_step(bitboards, mvs, train_generator=True)\n",
    "                RSv1.stockfish_train(bitboards, stk_mvs)\n",
    "                i += 1\n",
    "\n",
    "            print('Generator Training')\n",
    "            RSv1.on_epoch_end(epoch, G, prefix, val_data )\n",
    "            \n",
    "            if RSv1.logs[\"g_acc\"][-1] > save_thresh:\n",
    "                save_thresh = RSv1.logs[\"g_acc\"][-1]\n",
    "                torch.save(RSv1.generator, f\"{prefix}-acc_{save_thresh}.pt\")\n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
