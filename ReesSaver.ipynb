{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9bd546",
   "metadata": {},
   "source": [
    "# ReesSaver Discriminator Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d5507",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- Roughly 90% of our boards are unique\n",
    "- Every time you call generate_data it gets new games/games in a different order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df45d77a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:35:48.071109Z",
     "start_time": "2024-04-09T00:35:45.102784Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osama\\anaconda3\\lib\\site-packages\\torch\\__init__.py:690: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:453.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import chess\n",
    "\n",
    "import chess.svg\n",
    "import cv2\n",
    "from IPython.display import display, SVG\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from importlib import reload\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import utils\n",
    "reload(utils)\n",
    "import utils\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b917432f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:36:34.919081Z",
     "start_time": "2024-04-09T00:36:34.900079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Set default tensor type to CUDA tensors\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    " \n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "made_loader = False"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def clear_cuda():\n",
    "    \n",
    "    input()\n",
    "    \n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj):\n",
    "            if obj.is_cuda:\n",
    "                print(type(obj), obj.size(), obj.device)\n",
    "                del obj\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T00:36:35.679521Z",
     "start_time": "2024-04-09T00:36:35.672515Z"
    }
   },
   "id": "5e426489c167da5c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([64]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "clear_cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T04:06:11.654220Z",
     "start_time": "2024-04-07T04:06:10.594470Z"
    }
   },
   "id": "24b4c10246dd3c83",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils.Datasets import *\n",
    "\n",
    "import utils.Dataloading\n",
    "reload(utils.Dataloading)\n",
    "from utils.Dataloading import *\n",
    "from utils.Game_playing import *\n",
    "\n",
    "import utils.Playing_agents\n",
    "reload(utils.Playing_agents)\n",
    "from utils.Playing_agents import *\n",
    "\n",
    "from utils.CSV_data import *\n",
    "from utils.Puzzles import *"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:54:21.034826Z",
     "start_time": "2024-04-09T01:54:21.005821Z"
    }
   },
   "id": "aced8f27",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MLPv2_1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(14, 64, 3, 1, padding=1, padding_mode = 'zeros')\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        self.depth = 6\n",
    "\n",
    "        for _ in range(self.depth):\n",
    "            self.layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.layers.append(nn.BatchNorm2d(64))\n",
    "            self.layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.layers.append(nn.BatchNorm2d(64))\n",
    "\n",
    "        self.linear = nn.Linear(4096, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            j = i*4\n",
    "            ph = x.clone()\n",
    "            ph = self.layers[j](ph)\n",
    "            ph = self.layers[j+1](ph)\n",
    "            ph = F.relu(ph)\n",
    "            ph = self.layers[j+2](ph)\n",
    "            ph = self.layers[j+3](ph)\n",
    "\n",
    "            x = x + ph\n",
    "            x = F.relu(x)\n",
    "\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        minn, ila = x[:,:64], x[:,64:]\n",
    "\n",
    "        return minn, ila"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T00:36:43.397591Z",
     "start_time": "2024-04-09T00:36:43.387590Z"
    }
   },
   "id": "2e17ab646265886d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "RDv2 = torch.load(\"Models/RDv2.3 CB.pt\", map_location= device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:50:17.410499Z",
     "start_time": "2024-04-09T03:50:17.372225Z"
    }
   },
   "id": "34154737e9a1cf50",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 50000/50000 [16:40<00:00, 49.96it/s]\n"
     ]
    }
   ],
   "source": [
    "boards, meta, elo, moves, _, _, fens = generate_data(\"./Data/GAN_human_data.pgn\", N = 50_000)\n",
    "elo = [int(x) for x in elo]"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:19:09.581101Z",
     "start_time": "2024-04-09T01:00:42.269993Z"
    }
   },
   "id": "4d02f81d",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class generator_1(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_depth):\n",
    "\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(14, 64, 3, 1, padding=1, padding_mode = 'zeros')\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_depth = conv_depth\n",
    "        \n",
    "        for i in range(self.conv_depth):\n",
    "            self.conv_layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.conv_layers.append(nn.BatchNorm2d(64))\n",
    "            self.conv_layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            if i < self.conv_depth - 1:\n",
    "                self.conv_layers.append(nn.BatchNorm2d(64))\n",
    "\n",
    "        self.linear = nn.Linear(4096, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        for i in range(self.conv_depth):\n",
    "            j = i*4\n",
    "            ph = x.clone()\n",
    "            ph = self.conv_layers[j](ph)\n",
    "            ph = self.conv_layers[j+1](ph)\n",
    "            ph = F.relu(ph)\n",
    "            ph = self.conv_layers[j+2](ph)\n",
    "            if i < self.conv_depth - 1:\n",
    "                ph = self.conv_layers[j+3](ph)\n",
    "            \n",
    "            x = x + ph\n",
    "            x = F.relu(x)   \n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        minn, ila = x[:,:64], x[:,64:]\n",
    "\n",
    "        minn = F.softmax(minn, dim=1)\n",
    "        ila = F.softmax(ila, dim=1)\n",
    "\n",
    "        return torch.cat([minn, ila], dim=1).view(-1, 2, 8, 8)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:37:14.155072Z",
     "start_time": "2024-04-09T00:37:14.140063Z"
    }
   },
   "id": "bab89efa",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class discriminator_1(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_depth):\n",
    "\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(16, 64, 3, 1, padding=1, padding_mode = 'zeros')\n",
    "\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_depth = conv_depth\n",
    "\n",
    "        for _ in range(self.conv_depth):\n",
    "            self.conv_layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.conv_layers.append(nn.BatchNorm2d(64))\n",
    "            self.conv_layers.append(nn.Conv2d(64,64, 3, 1, padding=1, padding_mode = 'zeros'))\n",
    "            self.conv_layers.append(nn.BatchNorm2d(64))\n",
    "            \n",
    "        self.linear = nn.Linear(4096, 1)\n",
    "    \n",
    "\n",
    "    def forward(self, board, move):\n",
    "        \n",
    "        x = torch.cat((board, move), dim = 1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        for i in range(self.conv_depth):\n",
    "            j = i*4\n",
    "            ph = x.clone()\n",
    "            ph = self.conv_layers[j](ph)\n",
    "            ph = self.conv_layers[j+1](ph)\n",
    "            ph = F.leaky_relu(ph)\n",
    "            ph = self.conv_layers[j+2](ph)\n",
    "            ph = self.conv_layers[j+3](ph)\n",
    "            \n",
    "            x = x + ph\n",
    "            x = F.leaky_relu(x)\n",
    "                  \n",
    "                  \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:37:14.170302Z",
     "start_time": "2024-04-09T00:37:14.156071Z"
    }
   },
   "id": "da16f337",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GAN_1(nn.Module):\n",
    "    #AI: 0, Human: 1\n",
    "    def __init__(self, g_conv_depth, d_conv_depth, lr, pre_trained_g = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        print(device)\n",
    "        \n",
    "        if pre_trained_g is not None:\n",
    "            \n",
    "            self.generator = pre_trained_g\n",
    "            self.pre_trained = True\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.generator = generator_1(g_conv_depth)\n",
    "            self.pre_trained = False\n",
    "\n",
    "\n",
    "        self.discriminator = discriminator_1(d_conv_depth)\n",
    "        \n",
    "        self.logs = {\"g_acc\": [0], \"d_acc_r\": [0], \"d_acc_f\": [0], \n",
    "                     \"g_loss\": [0], \"d_loss\": [0],\"d_dist_f\": [0], \"d_dist_r\": [0], \n",
    "                     \"cur_g_loss\": 0, \"cur_d_loss\": 0}\n",
    "        \n",
    "        self.made_loader = False\n",
    "        \n",
    "        self.configure_optimizers(lr)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "    \n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "    \n",
    "    def train_step(self, train_boards, real_moves, train_generator):\n",
    "\n",
    "        epsilon = 1e-8\n",
    "        \n",
    "        #train generator\n",
    "        if train_generator:\n",
    "\n",
    "            self.opt_g.zero_grad()\n",
    "            \n",
    "            fake_moves = self(train_boards)\n",
    "            \n",
    "            if self.pre_trained:\n",
    "                \n",
    "                fake_moves = F.softmax(fake_moves[0], dim=1), F.softmax(fake_moves[1], dim=1)\n",
    "                fake_moves = torch.cat(fake_moves,dim=1).view(-1,2,8,8)\n",
    "            \n",
    "            y_hat = self.discriminator(train_boards, fake_moves)\n",
    "            \n",
    "            y = torch.zeros(real_moves.size(0), 1).to(device)\n",
    "            \n",
    "            g_loss = -1 * self.adversarial_loss(y_hat, y)\n",
    "            #g_loss = torch.sum(torch.log((y - y_hat) + epsilon), dim=0)\n",
    "                        \n",
    "            self.logs[\"cur_g_loss\"] += g_loss.item()\n",
    "            \n",
    "            g_loss.backward()\n",
    "\n",
    "            self.opt_g.step()\n",
    "              \n",
    "            \n",
    "        else:\n",
    "\n",
    "            self.opt_d.zero_grad()\n",
    "            \n",
    "            y_hat_real = self.discriminator(train_boards, real_moves)\n",
    "            y_real = torch.ones(real_moves.size(0), 1).to(device)\n",
    "            \n",
    "            #d_real_loss = torch.sum(y_hat_real, dim = 0)\n",
    "            d_real_loss = self.adversarial_loss(y_hat_real, y_real)\n",
    "            \n",
    "            fake_moves = self(train_boards)\n",
    "\n",
    "            if self.pre_trained:\n",
    "                fake_moves = F.softmax(fake_moves[0], dim=1), F.softmax(fake_moves[1], dim=1)\n",
    "                fake_moves = torch.cat(fake_moves,dim=1).view(-1,2,8,8).detach()\n",
    "\n",
    "            \n",
    "            y_hat_fake = self.discriminator(train_boards, fake_moves)\n",
    "            y_fake = torch.zeros(real_moves.size(0), 1).to(device)\n",
    "\n",
    "            #d_fake_loss = torch.sum(y_hat_fake, dim = 0)\n",
    "            d_fake_loss = self.adversarial_loss(y_hat_fake, y_fake)\n",
    "            \n",
    "            \n",
    "            d_loss = d_fake_loss + d_real_loss\n",
    "            self.logs[\"cur_d_loss\"] += d_loss.item()\n",
    "            \n",
    "            d_loss.backward()\n",
    "\n",
    "            self.opt_d.step()\n",
    "            \n",
    "            #for param in self.discriminator.parameters():\n",
    "            #    param.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "    \n",
    "    def configure_optimizers(self, lr):\n",
    "        self.lr = lr\n",
    "        self.opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas = (0.5, 0.999),  weight_decay=0.0)\n",
    "        self.opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr,  betas = (0.5, 0.999), weight_decay=0.0)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, G, val_data=None):\n",
    "        \n",
    "        self.logs[\"g_loss\"].append(self.logs[\"cur_g_loss\"] / G)\n",
    "        self.logs[\"d_loss\"].append(self.logs[\"cur_d_loss\"] / G)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} with g_loss: {self.logs[\"cur_g_loss\"] / G} and d_loss: {self.logs[\"cur_d_loss\"] / G}')\n",
    "        \n",
    "        self.logs[\"cur_g_loss\"] = 0\n",
    "        self.logs[\"cur_d_loss\"] = 0\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            \n",
    "            if val_data is not None:\n",
    "                \n",
    "                val_boards = val_data.bitboards\n",
    "                real_moves = val_data.moves\n",
    "                \n",
    "                #fake_moves_ind = torch.argmax(fake_moves, dim=1)\n",
    "                values = np.zeros(5)\n",
    "                \n",
    "                for i in range(0,len(val_boards), 100):\n",
    "                \n",
    "                    with torch.no_grad():\n",
    "                        \n",
    "                        curr_boards, curr_moves = val_boards[i:i+100], real_moves[i:i+100]\n",
    "    \n",
    "                        fake_moves = self(curr_boards)\n",
    "                                                \n",
    "                        if self.pre_trained:\n",
    "                            \n",
    "                            fake_from_moves = torch.argmax(fake_moves[0], dim=1)\n",
    "                            fake_to_moves = torch.argmax(fake_moves[1], dim=1)\n",
    "                            real_from_moves = torch.argmax(curr_moves[:,0].view(-1,64), dim=1)\n",
    "                            real_to_moves = torch.argmax(curr_moves[:,1].view(-1,64), dim=1)\n",
    "                            values[4] = torch.sum((fake_from_moves == real_from_moves) & (fake_to_moves == real_to_moves)).item()/fake_from_moves.size(0)\n",
    "                        \n",
    "                            fake_moves = torch.cat([F.softmax(fake_moves[0], dim=1), F.softmax(fake_moves[1], dim=1)], dim=1).view(-1,2,8,8)\n",
    "\n",
    "\n",
    "                        f_pred = self.discriminator(curr_boards, fake_moves)\n",
    "                        r_pred = self.discriminator(curr_boards, curr_moves)\n",
    "    \n",
    "                        values[0] += torch.mean(torch.round(f_pred) == 0, dtype=torch.float).item() #d_acc_f\n",
    "                        values[1] += torch.mean(torch.round(r_pred) == 1, dtype=torch.float).item() #d_acc_r\n",
    "    \n",
    "                        values[2] += torch.mean(torch.abs(f_pred)) #d_dist_f\n",
    "                        values[3] += torch.mean(torch.abs(1 - r_pred)) #d_dist_r\n",
    "\n",
    "                        if not self.pre_trained:\n",
    "    \n",
    "                            values[4] = torch.mean((curr_moves == torch.round(fake_moves)).all(dim=1), dtype=torch.float).item() # g_acc\n",
    "                                                    \n",
    "                n = int(len(val_boards) // 100)\n",
    "                d_acc_f, d_acc_r = values[0] / n, values[1] / n\n",
    "                d_dist_f, d_dist_r = values[2] / n, values[3] / n\n",
    "                g_acc = values[4] / n\n",
    "                \n",
    "                print(f'Epoch: {epoch+1}, {g_acc=}, {d_acc_f=}, {d_acc_r=}')\n",
    "                print(f\"{d_dist_f=}, {d_dist_r=}\")\n",
    "                \n",
    "                self.logs[\"d_acc_f\"].append(d_acc_f)\n",
    "                self.logs[\"d_acc_r\"].append(d_acc_r)\n",
    "                self.logs[\"d_dist_f\"].append(d_dist_f)\n",
    "                self.logs[\"d_dist_r\"].append(d_dist_r)\n",
    "                self.logs[\"g_acc\"].append(g_acc)\n",
    "                \n",
    "                \n",
    "            if epoch % 5 == 0:\n",
    "            \n",
    "                torch.save(self.generator, f\"generator {epoch}.pt\")\n",
    "                torch.save(self.discriminator, f\"discriminator {epoch}.pt\")\n",
    "            \n",
    "    def create_dataloader(self, boards, meta, moves, B, N, N_val):\n",
    "\n",
    "        if self.made_loader:\n",
    "\n",
    "            clear_cuda()\n",
    "            \n",
    "        loader = DataLoader(GANData(boards[:N], meta[:N], moves[:N]), batch_size = B, shuffle = True, generator=torch.Generator(device=device))\n",
    "        val_loader = GANData(boards[N:N+N_val], meta[N:N+N_val], moves[N:N+N_val])\n",
    "        \n",
    "        self.made_loader = True\n",
    "        \n",
    "        return loader, val_loader\n",
    "        \n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:46:59.076327Z",
     "start_time": "2024-04-09T03:46:59.043859Z"
    }
   },
   "id": "cf3c6fec864d134d",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GANData(Dataset):\n",
    "\n",
    "    def __init__(self, bitboards, white_turn, moves):\n",
    "\n",
    "        self.bitboards = torch.tensor(bitboards, dtype = torch.float).to(device)\n",
    "\n",
    "        self.moves = np.zeros((self.bitboards.size(dim=0), 128))\n",
    "\n",
    "        for ind, move in tqdm(enumerate(moves), total=len(moves)):\n",
    "\n",
    "            minn = move.from_square\n",
    "            ila = move.to_square\n",
    "        \n",
    "            if not white_turn[ind]:\n",
    "                minn = (63 - minn) // 8 * 8 + minn % 8\n",
    "                ila = (63 - ila) // 8 * 8 + ila % 8\n",
    "\n",
    "            self.moves[ind,minn] = 1\n",
    "            self.moves[ind, ila + 64] = 1\n",
    "            \n",
    "            \n",
    "        self.moves = torch.tensor(self.moves.reshape(-1,2,8,8), dtype = torch.float).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.moves.size(dim=0)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.bitboards[idx], self.moves[idx]\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T00:37:14.217302Z",
     "start_time": "2024-04-09T00:37:14.202301Z"
    }
   },
   "id": "4677947170615bf9",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clear_cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mclear_cuda\u001B[49m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'clear_cuda' is not defined"
     ]
    }
   ],
   "source": [
    "clear_cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:58:46.251619Z",
     "start_time": "2024-04-09T03:58:45.935380Z"
    }
   },
   "id": "e99e721a3307a923",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "del RSv1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:50:22.895411Z",
     "start_time": "2024-04-09T03:50:22.881411Z"
    }
   },
   "id": "4e0029868663dd9c",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "del loader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:03:20.697166Z",
     "start_time": "2024-04-09T03:03:20.682166Z"
    }
   },
   "id": "620dd96bb49cfb95",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "RSv1 = GAN_1(g_conv_depth=6, d_conv_depth=6, lr=0.0002, pre_trained_g=RDv2).to(device)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:50:25.051871Z",
     "start_time": "2024-04-09T03:50:25.033872Z"
    }
   },
   "id": "6b0cc09a",
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2300000/2300000 [00:03<00:00, 637866.60it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 500012.40it/s]\n"
     ]
    }
   ],
   "source": [
    "loader, val_data = RSv1.create_dataloader(boards, meta, moves, B = 512, N=2_300_000, N_val=5_000) # try B = 128\n",
    "G = len(loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:05:57.800405Z",
     "start_time": "2024-04-09T03:04:40.116210Z"
    }
   },
   "id": "813dd34e6b3493d9",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "del RSv1.discriminator\n",
    "\n",
    "RSv1.discriminator = discriminator_1(conv_depth=4)\n",
    "RSv1.configure_optimizers(0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:39:55.040593Z",
     "start_time": "2024-04-02T04:39:55.018509Z"
    }
   },
   "id": "ae05e0141e2312f6",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "del RSv1.generator\n",
    "\n",
    "RSv1.generator = generator_1(conv_depth=6)\n",
    "RSv1.configure_optimizers(0.0002)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T03:44:52.994668Z",
     "start_time": "2024-04-07T03:44:52.982663Z"
    }
   },
   "id": "4422e84a0c20287d",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_discriminator = False\n",
    "train_all = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:18:38.150816Z",
     "start_time": "2024-04-09T03:18:38.145817Z"
    }
   },
   "id": "2eb6651643a9eb0b",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for epoch in range(0,50):\n",
    "\n",
    "    reps = 0\n",
    "\n",
    "    if train_all or train_discriminator:\n",
    "\n",
    "        while RSv1.logs['d_acc_f'][-1] < 0.5:\n",
    "            \n",
    "            reps += 1\n",
    "            if reps > 5:\n",
    "                train_all = False\n",
    "                train_discriminator = False\n",
    "                break\n",
    "\n",
    "            i=0\n",
    "            \n",
    "            for bitboards, mvs in tqdm(loader):\n",
    "                if i > G // 8:\n",
    "                    break\n",
    "                RSv1.train_step(bitboards, mvs, train_generator=False)\n",
    "                i += 1\n",
    "\n",
    "            RSv1.on_epoch_end(epoch, G, val_data)\n",
    "\n",
    "    reps = 0\n",
    "    if train_all or not train_discriminator:\n",
    "\n",
    "        while RSv1.logs['d_acc_f'][-1] > 0.5:\n",
    "            reps += 1\n",
    "            if reps > 12:\n",
    "                train_all = False\n",
    "                train_discriminator = True\n",
    "                break\n",
    "\n",
    "            i=0\n",
    "            for bitboards, mvs in tqdm(loader):\n",
    "\n",
    "                if i > G // 8:\n",
    "                   break\n",
    "\n",
    "                RSv1.train_step(bitboards, mvs, train_generator=True)\n",
    "                i += 1\n",
    "\n",
    "            RSv1.on_epoch_end(epoch, G, val_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68ecb55a7a2f10f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [105]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m val_boards \u001B[38;5;241m=\u001B[39m val_data\u001B[38;5;241m.\u001B[39mbitboards\n\u001B[0;32m      2\u001B[0m real_moves \u001B[38;5;241m=\u001B[39m val_data\u001B[38;5;241m.\u001B[39mmoves\n\u001B[1;32m----> 4\u001B[0m minn, ila \u001B[38;5;241m=\u001B[39m \u001B[43mRDv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mval_boards\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m fake_from_moves \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(minn, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      8\u001B[0m fake_to_moves \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(ila, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36mMLPv2_1.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     25\u001B[0m j \u001B[38;5;241m=\u001B[39m i\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m4\u001B[39m\n\u001B[0;32m     26\u001B[0m ph \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mclone()\n\u001B[1;32m---> 27\u001B[0m ph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m ph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[j\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m](ph)\n\u001B[0;32m     29\u001B[0m ph \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(ph)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "val_boards = val_data.bitboards\n",
    "real_moves = val_data.moves\n",
    "\n",
    "minn, ila = RDv2(val_boards)\n",
    "\n",
    "\n",
    "fake_from_moves = torch.argmax(minn, dim=1)\n",
    "fake_to_moves = torch.argmax(ila, dim=1)\n",
    "real_from_moves = torch.argmax(real_moves[:,0].view(-1,64), dim=1)\n",
    "real_to_moves = torch.argmax(real_moves[:,1].view(-1,64), dim=1)\n",
    "torch.sum((fake_from_moves == real_from_moves) & (fake_to_moves == real_to_moves))/fake_from_moves.size(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T03:55:41.085999Z",
     "start_time": "2024-04-09T03:55:40.192368Z"
    }
   },
   "id": "16b09e78fe015185",
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "old_generator = torch.load(\"Models/RDv2.3 CB.pt\")\n",
    "#old_discriminator = torch.load(\"discriminator 15.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T00:49:33.885036Z",
     "start_time": "2024-04-09T00:49:33.856018Z"
    }
   },
   "id": "2aa444e6c058731b",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:48<00:00,  1.48it/s]\n",
      "100%|██████████| 250/250 [01:59<00:00,  2.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(114, 228, 158, 0.228)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_against(old_generator_model, generator_model, N=500)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T02:04:09.452085Z",
     "start_time": "2024-04-09T01:59:21.441296Z"
    }
   },
   "id": "aa4d829c",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "old_generator_model = lambda x: network_agent_prob_conv(x, lambda y: old_generator(y))\n",
    "generator_model = lambda x: network_agent_prob_conv(x, lambda y: RSv1.generator(y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T00:51:36.896164Z",
     "start_time": "2024-04-09T00:51:36.890164Z"
    }
   },
   "id": "30a042950898223c",
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stockfish Section"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a41802f165d1c26b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import chess.engine\n",
    "\n",
    "Stockfish_path = \"stockfish/stockfish-windows-x86-64-avx2.exe\"\n",
    "\n",
    "engine = chess.engine.SimpleEngine.popen_uci(r\"C:\\Users\\xxxxx\\Downloads\\stockfish_14_win_x64\\stockfish_14_win_x64_avx2.exe\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8fd9e76d4e5628d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
